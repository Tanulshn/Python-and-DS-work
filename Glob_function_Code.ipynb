{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glob function Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1cfRKoekB-PGxEijBFkYpAxf0hne1d-5K",
      "authorship_tag": "ABX9TyMYSlv4ZaY3t/YlSbBQo4mG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanulshn/Python-and-DS-work/blob/main/Glob_function_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMbUYTuAdw7x"
      },
      "source": [
        "#Objective \n",
        "To perform glob glob package on a collection of csv files and deriving Dataframes out of it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PplSzRd5oq_C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPqwLp4ablp6"
      },
      "source": [
        "import glob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFfESSObm8n",
        "outputId": "6460377f-024d-4178-b1c9-b1778ad27e57"
      },
      "source": [
        "file_list = []\n",
        "\n",
        "for file_name in glob.glob('/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/'+'*.csv'):\n",
        "  print(file_name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Grasim ind.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Bank of Baroda.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Exide Ind.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Adani Ports.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Dr Reddys.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Jindal Steel.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/IOC.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/HDFC Bank.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Bajaj Auto.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Divis.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Havells.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Dabur.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/CCIL.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Axis.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Bank of India.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Colgate Palmolive.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/HUL.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Adani Power.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Asian Paints.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Canara Bank.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/GodrejConsumer.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/ICICI.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Kotak bank.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Hindalco.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Oil India.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/L&T.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Pidilite.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/TATA Steel.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/NALCO.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/United Spirits.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Wipro.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Bajaj Finserv.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Vedanta.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Britannia.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Bosch.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Cipla.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/GSK Pharma.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/HCL Tech.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Cmmins.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/HPCL.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/BergerPaint.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Hero Motors.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Infosys.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/ITC.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/JSW Steel.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/M&M.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Maruti.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Jubilant.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Mindtree.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Marico.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/MRF.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/ONGC.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/PageInd.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/PNB.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Sun Pharma.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Shree Cement.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Reliance Industries.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/SBI Bank.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/TATA Power.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Ultratech.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/TATA GloBev.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/TechM.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/TCS.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/TATA Motors.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/Titan.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al5gQLMoZ_89"
      },
      "source": [
        "These file names can not be used as laels, so we have to get refined version of each file name for labeling prpose "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5Ye7fKe51l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0d9301-1c36-4f6a-a89d-cc1f27fa931a"
      },
      "source": [
        "file_list = []\n",
        "\n",
        "for file_name in glob.glob('/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/'+'*.csv'):\n",
        "  co_name = file_name.split('/')[-1]\n",
        "  name = co_name.split('.')[0]\n",
        "  print(name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grasim ind\n",
            "Bank of Baroda\n",
            "Exide Ind\n",
            "Adani Ports\n",
            "Dr Reddys\n",
            "Jindal Steel\n",
            "IOC\n",
            "HDFC Bank\n",
            "Bajaj Auto\n",
            "Divis\n",
            "Havells\n",
            "Dabur\n",
            "CCIL\n",
            "Axis\n",
            "Bank of India\n",
            "Colgate Palmolive\n",
            "HUL\n",
            "Adani Power\n",
            "Asian Paints\n",
            "Canara Bank\n",
            "GodrejConsumer\n",
            "ICICI\n",
            "Kotak bank\n",
            "Hindalco\n",
            "Oil India\n",
            "L&T\n",
            "Pidilite\n",
            "TATA Steel\n",
            "NALCO\n",
            "United Spirits\n",
            "Wipro\n",
            "Bajaj Finserv\n",
            "Vedanta\n",
            "Britannia\n",
            "Bosch\n",
            "Cipla\n",
            "GSK Pharma\n",
            "HCL Tech\n",
            "Cmmins\n",
            "HPCL\n",
            "BergerPaint\n",
            "Hero Motors\n",
            "Infosys\n",
            "ITC\n",
            "JSW Steel\n",
            "M&M\n",
            "Maruti\n",
            "Jubilant\n",
            "Mindtree\n",
            "Marico\n",
            "MRF\n",
            "ONGC\n",
            "PageInd\n",
            "PNB\n",
            "Sun Pharma\n",
            "Shree Cement\n",
            "Reliance Industries\n",
            "SBI Bank\n",
            "TATA Power\n",
            "Ultratech\n",
            "TATA GloBev\n",
            "TechM\n",
            "TCS\n",
            "TATA Motors\n",
            "Titan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7u0ua7RaHKz"
      },
      "source": [
        "VOILA!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6P23yMEaMnS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-rZM49XaMlK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6cJ2HI2a3gc"
      },
      "source": [
        "Now, we have toread multiple files and create a dataframe with a time series having all the columns added one after the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb2xeWkb1Kfy"
      },
      "source": [
        "# # Now, we need to concat the files with their names as (Filename_ Colnames) format\n",
        "# lst_dfs = []\n",
        "# data = pd.DataFrame()\n",
        "\n",
        "# for file in file_list:\n",
        "#     df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/'+file+'.csv', infer_datetime_format= True)\n",
        "    \n",
        "#     for i in ['Std','Mcap','Con']:\n",
        "#       df[i]= pd.to_numeric(df[i], errors= 'coerce').round(2)\n",
        "\n",
        "#     df = df[['Date','Std','Con']]\n",
        "#     df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
        "#     df.set_index('Date',  inplace=True)\n",
        "#     df= df.resample('d').last()\n",
        "#     df = df.add_suffix(f'_{file}')\n",
        "#     data = data.join(df, how = 'outer')\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3fvyEthrKxq",
        "outputId": "00d23fe8-c649-4009-f9bc-250eb19811df"
      },
      "source": [
        "data= pd.DataFrame()\n",
        "\n",
        "for file_name in glob.glob('/content/drive/MyDrive/Colab Notebooks/0-1: Valuation/CSV Files/'+'*.csv'):\n",
        "  df = pd.read_csv(file_name)\n",
        "  \n",
        "  #Convert the datatype from object to float\n",
        "  for i in ['Std','Con']:\n",
        "    df[i] = pd.to_numeric(df[i], errors= 'coerce').round(2)\n",
        "\n",
        "  df = df[['Date','Std','Con']]\n",
        "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=False) # Use dayfirst function carefully\n",
        "  df.set_index('Date', inplace=True) # Set the Date Column to Index\n",
        "  df = df.resample('m').last() # Set the frequency to Business days\n",
        "  #df.fillna(method='ffill') # Fill the nan values\n",
        "\n",
        "  # Create a string for the suffix \n",
        "  name= file_name.split('/')[-1]\n",
        "  suffix = name.split('.')[0]\n",
        "  df = df.add_suffix(f'_{suffix}')\n",
        "\n",
        "  # Join the Time series along the column\n",
        "  data= data.join(df, how='outer')\n",
        "  \n",
        "  # print(name)\n",
        "  # print(df.head(10),'\\n\\n')\n",
        "\n",
        "\n",
        "#data.head(20)\n",
        "data.isnull().sum()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Std_Grasim ind        0\n",
              "Con_Grasim ind        0\n",
              "Std_Bank of Baroda    0\n",
              "Con_Bank of Baroda    0\n",
              "Std_Exide Ind         0\n",
              "                     ..\n",
              "Con_TCS               0\n",
              "Std_TATA Motors       0\n",
              "Con_TATA Motors       0\n",
              "Std_Titan             0\n",
              "Con_Titan             0\n",
              "Length: 130, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3FTDOrztADW"
      },
      "source": [
        "data.tail(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxDm0XD_icj2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}